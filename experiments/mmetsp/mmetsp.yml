name: mmetsp

experiments:
  phylum: &exp_options
    expand_options:
      k: 4..6
      sample_len: [150000, 500000, 50000, 10000, 5000]
      samples_per_organism: [1, 5, 10]
    min_group_pts: 8
    taxonomy_index: 2
    dataset:
      archive: mmetsp
      archive_folder: nt
      metadata: mmetsp
    groups: |
      lambda options, metadata:
        import collections
        counts = collections.Counter(x['taxonomy'].split('; ')[options['taxonomy_index']] for x in metadata)
        omit_groups = {'NULL', 'Unknown'}
        return {v: {'taxonomy_str': v} for v in counts if v and v not in omit_groups and counts[v] >= options['min_group_pts']}

  class:
    <<: *exp_options
    taxonomy_index: 3

  order:
    <<: *exp_options
    taxonomy_index: 4

  family:
    <<: *exp_options
    taxonomy_index: 5

  genus:
    <<: *exp_options
    taxonomy_index: 6

steps:
  - type: select
    copy_for_options: [k]
    pick_group: |
      lambda metadata, group_options, options:
        # these ids are in either nt or cds but not both, we omit them entirely
        omit_ids = {'MMETSP0133', 'MMETSP0134', 'MMETSP0135', 'MMETSP0197', 'MMETSP0399', 'MMETSP0452', 'MMETSP0923', 'MMETSP0925', 'MMETSP0705', 'MMETSP0716', 'MMETSP0719',
        # these are too short for unique samples
                     'MMETSP0018', 'MMETSP0044', 'MMETSP0186', 'MMETSP0210', 'MMETSP0223', 'MMETSP0225', 'MMETSP0229', 'MMETSP0251', 'MMETSP0252', 'MMETSP0347', 'MMETSP0451', 'MMETSP0705', 'MMETSP0716', 'MMETSP0719', 'MMETSP0924', 'MMETSP1018', 'MMETSP1019', 'MMETSP1147', 'MMETSP1148', 'MMETSP1317'}
        return [x for x in metadata if x['id'] not in omit_ids and group_options['taxonomy_str'] == x['taxonomy'].split('; ')[options['taxonomy_index']]]
    postprocess: |
      lambda metadata_entry, entry_sequences, options:
        import numpy as np
        samples = []
        for _ in range(options['samples_per_organism']):
          seq = ''
          choices = []
          random_indexes = np.random.permutation(len(entry_sequences)).tolist()
          while len(seq) < options['sample_len']:
            idx = random_indexes.pop()
            choices.append(idx)
            seq += entry_sequences[idx]
          samples.append((dict(metadata_entry, sample_indexes=choices), [seq]))
        return samples

  - type: kmers
    output_file: cgrs.mm-repr
    mode: counts
    k: from_options
    bits_per_element: 32

  - &classify_options
    type: classify
    features_file: cgrs.mm-repr
    output_file: classification-cgrs.json
    validation_count: 10
    validation_split_by: id
    classifiers:
      - 10-nearest-neighbors
      - nearest-centroid-mean
      - nearest-centroid-median
      - logistic-regression
      - sgd
      - linear-svm
      - quadratic-svm
      - cubic-svm
      - decision-tree
      - random-forest
      - adaboost
      - gaussian-naive-bayes
      - lda
      - qda
      - multilayer-perceptron
